{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6Santiago9/Entregas/blob/main/99%20-%20modelo%20soluci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOLsEWtzfxOr"
      },
      "source": [
        "# Importación de Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTfWxDLvfqZu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import unicodedata\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPukDUBLijNW"
      },
      "source": [
        "# Configuración Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmGLfbJif68Q"
      },
      "outputs": [],
      "source": [
        "# Establecer tus credenciales de Kaggle\n",
        "os.environ['KAGGLE_USERNAME'] = 'cesarmartinezia'\n",
        "os.environ['KAGGLE_KEY'] = '3bd3c2a5994356c24295cd5c6d8bba59'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qkm-QpSSiSAa"
      },
      "outputs": [],
      "source": [
        "# Crear manualmente el archivo kaggle.json a partir de esas variables\n",
        "!mkdir -p ~/.kaggle\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "    f.write('{\"username\":\"%s\",\"key\":\"%s\"}' % (os.environ['KAGGLE_USERNAME'], os.environ['KAGGLE_KEY']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9etXoxfiZfp"
      },
      "outputs": [],
      "source": [
        "# Ajustar permisos\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hLVqXc0imsd"
      },
      "source": [
        "# Descarga de Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p9EqZC0iaon",
        "outputId": "658f623b-eaba-448f-aad0-a78f72cf07d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to /content\n",
            "\r  0% 0.00/29.9M [00:00<?, ?B/s]\n",
            "\r100% 29.9M/29.9M [00:00<00:00, 670MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Descargar los datos de la competencia\n",
        "!kaggle competitions download -c udea-ai-4-eng-20252-pruebas-saber-pro-colombia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tD9SbiGf9ga",
        "outputId": "9d528868-f30f-44cb-ace2-78bb7a46caba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip\n",
            "  inflating: submission_example.csv  \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DOYaIg8gD8R"
      },
      "source": [
        "# Cargar el train y test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxSTGQW3gCs4"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2ZoCOA3jBO9",
        "outputId": "9952b169-a082-4da9-cab9-f0a86cfd41a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(692500, 21) (296786, 20)\n"
          ]
        }
      ],
      "source": [
        "# Tamaño del dataset\n",
        "print(df.shape, test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBDxzZ7d9LQ1"
      },
      "source": [
        "# Limpieza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Eliminar columnas con poca variabilidad\n",
        "def columnas_baja_variabilidad(data, threshold=0.99):\n",
        "    columnas_remover = []\n",
        "    for col in data.columns:\n",
        "        top_freq = data[col].value_counts(normalize=True, dropna=False).max()\n",
        "        if top_freq >= threshold:\n",
        "            columnas_remover.append(col)\n",
        "    return columnas_remover\n",
        "\n",
        "# 2. Detectamos columnas malas en train\n",
        "\n",
        "cols_baja_var = columnas_baja_variabilidad(df, threshold=0.99)\n",
        "print(\"Columnas con poca variabilidad:\", len(cols_baja_var))\n",
        "print(cols_baja_var[:20])  # primeras 20\n",
        "\n",
        "# 3. Eliminamos en train y test\n",
        "\n",
        "df.drop(columns=cols_baja_var, inplace=True)\n",
        "test.drop(columns=cols_baja_var, inplace=True)\n",
        "\n",
        "print(\"Nuevo shape train:\", df.shape)\n",
        "print(\"Nuevo shape test:\", test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7lp6ghtNsc3",
        "outputId": "0c54c4b4-1382-409b-c4ab-fc06741dd521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas con poca variabilidad: 1\n",
            "['E_PRIVADO_LIBERTAD']\n",
            "Nuevo shape train: (692500, 20)\n",
            "Nuevo shape test: (296786, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Eliminar columnas con demasiado NaN\n",
        "\n",
        "umbral_nan = 0.60\n",
        "\n",
        "cols_muchos_nan = df.columns[df.isna().mean() > umbral_nan].tolist()\n",
        "\n",
        "print(\"Columnas con demasiados NaN:\", len(cols_muchos_nan))\n",
        "print(cols_muchos_nan[:20])\n",
        "\n",
        "df.drop(columns=cols_muchos_nan, inplace=True)\n",
        "test.drop(columns=cols_muchos_nan, inplace=True)\n",
        "\n",
        "print(\"Shape después de eliminar columnas con NaN:\")\n",
        "print(\"Train:\", df.shape)\n",
        "print(\"Test:\", test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzywKzA5OBDG",
        "outputId": "49fc9888-249a-43fd-aefe-36e246ee0f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columnas con demasiados NaN: 0\n",
            "[]\n",
            "Shape después de eliminar columnas con NaN:\n",
            "Train: (692500, 20)\n",
            "Test: (296786, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Imputación de valores faltantes\n",
        "\n",
        "# Columna objetivo\n",
        "target = \"RENDIMIENTO_GLOBAL\"\n",
        "\n",
        "# Identificar columnas categóricas EXCLUYENDO la etiqueta\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "cat_cols = [c for c in cat_cols if c != target]\n",
        "\n",
        "# Columnas numéricas\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Imputación numérica: mediana\n",
        "for col in num_cols:\n",
        "    mediana = df[col].median()\n",
        "    df[col].fillna(mediana, inplace=True)\n",
        "    test[col].fillna(mediana, inplace=True)\n",
        "\n",
        "# Imputación categórica (sin tocar la etiqueta)\n",
        "for col in cat_cols:\n",
        "    df[col].fillna(\"DESCONOCIDO\", inplace=True)\n",
        "    test[col].fillna(\"DESCONOCIDO\", inplace=True)\n",
        "\n",
        "print(\"Imputación lista ✔\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4f0HF1rOlBZ",
        "outputId": "98bd47ef-4a18-4419-c47b-3fc89492e4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-677779088.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(mediana, inplace=True)\n",
            "/tmp/ipython-input-677779088.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(mediana, inplace=True)\n",
            "/tmp/ipython-input-677779088.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[col].fillna(\"DESCONOCIDO\", inplace=True)\n",
            "/tmp/ipython-input-677779088.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  test[col].fillna(\"DESCONOCIDO\", inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputación lista ✔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Unificar categorías entre Train y Test\n",
        "\n",
        "# Obtener columnas categóricas otra vez (sin etiqueta)\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "cat_cols = [c for c in cat_cols if c != 'RENDIMIENTO_GLOBAL']\n",
        "\n",
        "for col in cat_cols:\n",
        "    # Convertir a string por seguridad (evita errores de tipo)\n",
        "    df[col] = df[col].astype(str)\n",
        "    test[col] = test[col].astype(str)\n",
        "\n",
        "    # Unificar categorías usando categorías combinadas\n",
        "    categorias = list(set(df[col].unique()) | set(test[col].unique()))\n",
        "\n",
        "    df[col] = pd.Categorical(df[col], categories=categorias)\n",
        "    test[col] = pd.Categorical(test[col], categories=categorias)\n",
        "\n",
        "print(\"✔ Categorías unificadas entre train y test\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrNKSO2uOyud",
        "outputId": "32ae57c0-ef5f-400c-d60c-7a1ea07b9142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Categorías unificadas entre train y test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 7. Label Encoding para TODAS las categóricas\n",
        "\n",
        "label_encoders = {}\n",
        "cat_cols = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
        "cat_cols = [c for c in cat_cols if c != \"RENDIMIENTO_GLOBAL\"]  # evitar target\n",
        "\n",
        "for col in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    # fit en train + test juntos (para no perder categorías)\n",
        "    le.fit(list(df[col].astype(str).values) + list(test[col].astype(str).values))\n",
        "\n",
        "    df[col] = le.transform(df[col].astype(str))\n",
        "    test[col] = le.transform(test[col].astype(str))\n",
        "\n",
        "    label_encoders[col] = le\n",
        "\n",
        "print(\"✔ Todas las variables categóricas fueron codificadas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8OAEH6wO-SB",
        "outputId": "1a741e9a-e8a5-42f0-c091-6272a06f5fe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔ Todas las variables categóricas fueron codificadas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GblxjaMevHj7"
      },
      "outputs": [],
      "source": [
        "# 8. Agrupar en una solo columna lo que no ayuda en nada\n",
        "df.F_EDUCACIONMADRE = ['Ninguno' if i in ['No sabe', 'No Aplica'] else i for i in df.F_EDUCACIONMADRE.values]\n",
        "df.F_EDUCACIONPADRE = ['Ninguno' if i in ['No sabe', 'No Aplica'] else i for i in df.F_EDUCACIONPADRE.values]\n",
        "test.F_EDUCACIONMADRE = ['Ninguno' if i in ['No sabe', 'No Aplica'] else i for i in test.F_EDUCACIONMADRE.values]\n",
        "test.F_EDUCACIONPADRE = ['Ninguno' if i in ['No sabe', 'No Aplica'] else i for i in test.F_EDUCACIONPADRE.values]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHjLPc_Gq-8X"
      },
      "outputs": [],
      "source": [
        "# 9. Convertir variables categoricas en numericas\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['F_TIENELAVADORA'] = le.fit_transform(df['F_TIENELAVADORA']) # Aqui el 1 es si y 0 es no\n",
        "df['F_TIENEINTERNET'] = le.fit_transform(df['F_TIENEINTERNET']) # Aqui el 1 es si y 0 es no\n",
        "df['F_TIENEAUTOMOVIL'] = le.fit_transform(df['F_TIENEAUTOMOVIL']) # Aqui el 1 es si y 0 es no\n",
        "df['E_PAGOMATRICULAPROPIO'] = le.fit_transform(df['E_PAGOMATRICULAPROPIO']) # Aqui el 1 es si y 0 es no\n",
        "df['F_TIENECOMPUTADOR'] = le.fit_transform(df['F_TIENECOMPUTADOR']) # Aqui el 1 es s y 0 es n\n",
        "test['F_TIENELAVADORA'] = le.fit_transform(test['F_TIENELAVADORA']) # Aqui el 1 es si y 0 es no\n",
        "test['F_TIENEINTERNET'] = le.fit_transform(test['F_TIENEINTERNET']) # Aqui el 1 es si y 0 es no\n",
        "test['F_TIENEAUTOMOVIL'] = le.fit_transform(test['F_TIENEAUTOMOVIL']) # Aqui el 1 es si y 0 es no\n",
        "test['E_PAGOMATRICULAPROPIO'] = le.fit_transform(test['E_PAGOMATRICULAPROPIO']) # Aqui el 1 es si y 0 es no\n",
        "test['F_TIENECOMPUTADOR'] = le.fit_transform(test['F_TIENECOMPUTADOR']) # Aqui el 1 es s y 0 es n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OI3jRrOLlEj5"
      },
      "outputs": [],
      "source": [
        "# 10. Aplico OneHot\n",
        "df = df.copy()\n",
        "df = pd.get_dummies(df, columns=['E_PRGM_DEPARTAMENTO'], dtype=int)\n",
        "df = pd.get_dummies(df, columns=['F_EDUCACIONMADRE'], dtype=int)\n",
        "df = pd.get_dummies(df, columns=['F_EDUCACIONPADRE'], dtype=int)\n",
        "df = pd.get_dummies(df, columns=['E_VALORMATRICULAUNIVERSIDAD'], dtype=int)\n",
        "df = pd.get_dummies(df, columns=['E_HORASSEMANATRABAJA'], dtype=int)\n",
        "df = pd.get_dummies(df, columns=['F_ESTRATOVIVIENDA'], dtype=int)\n",
        "test = test.copy()\n",
        "test = pd.get_dummies(test, columns=['E_PRGM_DEPARTAMENTO'], dtype=int)\n",
        "test = pd.get_dummies(test, columns=['F_EDUCACIONMADRE'], dtype=int)\n",
        "test = pd.get_dummies(test, columns=['F_EDUCACIONPADRE'], dtype=int)\n",
        "test = pd.get_dummies(test, columns=['E_VALORMATRICULAUNIVERSIDAD'], dtype=int)\n",
        "test = pd.get_dummies(test, columns=['E_HORASSEMANATRABAJA'], dtype=int)\n",
        "test = pd.get_dummies(test, columns=['F_ESTRATOVIVIENDA'], dtype=int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "#  Separar X e y\n",
        "y = df[\"RENDIMIENTO_GLOBAL\"]\n",
        "X = df.drop(columns=[\"RENDIMIENTO_GLOBAL\"])\n",
        "\n",
        "test_IDs = test[\"ID\"]\n",
        "X_test = test.drop(columns=[\"ID\"])\n",
        "\n",
        "#  Codificar target\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "print(\"Clases codificadas:\", dict(zip(le.classes_, le.transform(le.classes_))))\n",
        "\n",
        "#  Train / Valid\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "#  Configuración\n",
        "model = lgb.LGBMClassifier(\n",
        "    boosting_type=\"gbdt\",\n",
        "    objective=\"multiclass\",\n",
        "    num_class=len(le.classes_),\n",
        "\n",
        "    # Parámetros optimizados\n",
        "    n_estimators=1500,\n",
        "    learning_rate=0.02,\n",
        "    num_leaves=64,\n",
        "    max_depth=-1,\n",
        "\n",
        "    feature_fraction=0.80,      # Esto reduce overfitting\n",
        "    bagging_fraction=0.75,\n",
        "    bagging_freq=5,\n",
        "\n",
        "    min_data_in_leaf=50,\n",
        "    lambda_l1=1.0,\n",
        "    lambda_l2=1.0,\n",
        "\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "#  Entrenamiento con callbacks\n",
        "from lightgbm import log_evaluation\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_valid, y_valid)],\n",
        "    eval_metric=\"multi_logloss\",\n",
        "    callbacks=[log_evaluation(200)]  # Muestra evaluación cada 200 iteraciones\n",
        ")\n",
        "\n",
        "#  Evaluación\n",
        "y_pred = model.predict(X_valid)\n",
        "acc = accuracy_score(y_valid, y_pred)\n",
        "\n",
        "print(f\"\\n ACCURACY OPTIMIZADO: {acc:.5f}\")\n",
        "\n",
        "#  Alinear columnas antes de predecir\n",
        "\n",
        "# Columnas que están en train pero no en test\n",
        "missing_cols = set(X_train.columns) - set(X_test.columns)\n",
        "\n",
        "# Crear las columnas faltantes en test\n",
        "for col in missing_cols:\n",
        "    X_test[col] = 0  # Valor seguro para LightGBM\n",
        "\n",
        "# Ordenar columnas del test igual que train\n",
        "X_test = X_test[X_train.columns]\n",
        "\n",
        "#  Predicciones finales\n",
        "test_pred = model.predict(X_test)\n",
        "test_pred_labels = le.inverse_transform(test_pred)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test_IDs,\n",
        "    \"RENDIMIENTO_GLOBAL\": test_pred_labels\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission1.csv\", index=False)\n",
        "print(\"\\n submission1.csv generado correctamente!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06kATEMZPkD7",
        "outputId": "ae60ee21-e0ae-4150-af76-71000ade08b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases codificadas: {'alto': np.int64(0), 'bajo': np.int64(1), 'medio-alto': np.int64(2), 'medio-bajo': np.int64(3)}\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050531 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1564\n",
            "[LightGBM] [Info] Number of data points in the train set: 554000, number of used features: 89\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
            "[LightGBM] [Info] Start training from score -1.372285\n",
            "[LightGBM] [Info] Start training from score -1.386915\n",
            "[LightGBM] [Info] Start training from score -1.394559\n",
            "[LightGBM] [Info] Start training from score -1.391565\n",
            "[200]\tvalid_0's multi_logloss: 1.21564\n",
            "[400]\tvalid_0's multi_logloss: 1.20082\n",
            "[600]\tvalid_0's multi_logloss: 1.19639\n",
            "[800]\tvalid_0's multi_logloss: 1.19454\n",
            "[1000]\tvalid_0's multi_logloss: 1.19364\n",
            "[1200]\tvalid_0's multi_logloss: 1.19263\n",
            "[1400]\tvalid_0's multi_logloss: 1.19231\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
            "\n",
            " ACCURACY OPTIMIZADO: 0.43885\n",
            "[LightGBM] [Warning] min_data_in_leaf is set=50, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=50\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.75, subsample=1.0 will be ignored. Current value: bagging_fraction=0.75\n",
            "\n",
            " submission1.csv generado correctamente!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}